{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d99428-8560-41f0-b6d2-8b9a6db580c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import time\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b91d67-5e4f-4d0f-8a79-72b940fa0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify dataset path\n",
    "dataset_path = \"E:/SML Project/plantvillagedataset/color\"  # Update with the correct path\n",
    "\n",
    "# Define ImageDataGenerator for preprocessing and augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,            # Normalize pixel values\n",
    "    validation_split=0.2,      # Split dataset: 80% train, 20% validation\n",
    "    rotation_range=30,         # Random rotations\n",
    "    zoom_range=0.2,            # Random zoom\n",
    "    horizontal_flip=True       # Random horizontal flips\n",
    ")\n",
    "\n",
    "# Prepare training data generator (resize images to (224, 224))\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),  # Resize images to (224, 224) to match MobileNet's input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='training',         # Use the 'training' subset for training data\n",
    "    shuffle=True               # Shuffle the data\n",
    ")\n",
    "\n",
    "# Prepare validation data generator (resize images to (224, 224))\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(224, 224),  # Resize images to (224, 224) to match MobileNet's input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical', # Multi-class classification\n",
    "    subset='validation',      # Use the 'validation' subset for validation data\n",
    "    shuffle=False             # Don't shuffle validation data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70552d37-b9fb-4a44-9f83-b0835331d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MobileNet model pre-trained on ImageNet without the top layers\n",
    "mobilenet_base = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the pre-trained layers to retain learned features\n",
    "for layer in mobilenet_base.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    mobilenet_base,  # Add the pre-trained MobileNet base\n",
    "    GlobalAveragePooling2D(),  # Replace Flatten with GlobalAveragePooling for better performance\n",
    "    Dense(128, activation='relu'),  # Add a dense layer for learning task-specific features\n",
    "    Dropout(0.5),  # Regularization to reduce overfitting\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3af488-4c63-4098-85ea-59809dace432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom callback to display remaining time during training\n",
    "class TimeRemainingCallback(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.train_start_time = time.time()  # Record the training start time\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch == 0:\n",
    "            self.epoch_start_time = time.time()  # Record the first epoch start time\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_time = time.time()\n",
    "        time_per_epoch = current_time - self.epoch_start_time\n",
    "        remaining_epochs = self.params['epochs'] - (epoch + 1)\n",
    "        estimated_time_remaining = time_per_epoch * remaining_epochs\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{self.params['epochs']} completed.\")\n",
    "        print(f\"Time per epoch: {time_per_epoch:.2f} seconds.\")\n",
    "        print(f\"Estimated time remaining: {estimated_time_remaining:.2f} seconds.\\n\")\n",
    "\n",
    "        # Update epoch start time for the next epoch\n",
    "        self.epoch_start_time = current_time\n",
    "\n",
    "# Instantiate the custom callback\n",
    "time_remaining_callback = TimeRemainingCallback()\n",
    "\n",
    "# Train the model with the custom callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=5,  # Adjust epochs as needed\n",
    "    validation_data=validation_generator,  # Use validation data for evaluation\n",
    "    callbacks=[time_remaining_callback]  # Add the custom callback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9189a4d-423b-4954-b7bb-330df80498e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot training vs. validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2baade-027a-4444-a760-a7daae2a506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training vs Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b30870-5c94-47ce-9ab3-3344ee2be1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "# Assuming the model is already loaded and trained, and it's named 'model'\n",
    "# If not, you can load the model using model = tf.keras.models.load_model('model_path')\n",
    "\n",
    "# Load and preprocess an image for prediction\n",
    "img_path = r\"C:\\Users\\HP\\Downloads\\img.JPG\"  # Correct the path format\n",
    "\n",
    "# Resize the image to match model input size (224x224 as expected by your model)\n",
    "img = image.load_img(img_path, target_size=(224, 224))  # Resize to model input size\n",
    "img_array = image.img_to_array(img) / 255.0  # Convert image to array and normalize pixel values\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension for prediction\n",
    "\n",
    "# Predict the disease class\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the index of the class with the highest probability\n",
    "\n",
    "# Map the predicted index to class labels\n",
    "class_names = list(train_generator.class_indices.keys())  # Get the class labels from the training data generator\n",
    "predicted_class = class_names[predicted_class_index]  # Get the predicted class name\n",
    "print(f\"The predicted class is: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb64e8-63b8-44d1-a152-461fb4fbc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you already have a trained model and validation generator\n",
    "validation_labels = []\n",
    "validation_predicted_classes = []\n",
    "\n",
    "# Iterate over the validation data generator and collect true labels and predictions\n",
    "for batch in validation_generator:\n",
    "    # Get the true labels from the generator\n",
    "    true_labels = batch[1]\n",
    "    validation_labels.extend(np.argmax(true_labels, axis=1))  # Convert one-hot encoding to labels\n",
    "\n",
    "    # Get the predictions from the model\n",
    "    predictions = model.predict(batch[0])\n",
    "    predicted_classes = np.argmax(predictions, axis=1)  # Get the predicted class labels\n",
    "    validation_predicted_classes.extend(predicted_classes)\n",
    "\n",
    "# Now you can generate the classification report\n",
    "report = classification_report(validation_labels, validation_predicted_classes, \n",
    "                               target_names=validation_generator.class_indices.keys(), zero_division=0)\n",
    "\n",
    "# Print the classification report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40205eed-91e6-4bf0-b5d6-f882f69daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for future use\n",
    "model.save(\"Model-mobilnet.h5\")\n",
    "print(\"Model-mobilnet.h5\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
