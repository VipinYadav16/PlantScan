{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d99428-8560-41f0-b6d2-8b9a6db580c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"keras\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b91d67-5e4f-4d0f-8a79-72b940fa0a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify dataset path\n",
    "dataset_path = \"E:/SML Project/plantvillagedataset/color\"  \n",
    "\n",
    "# Define ImageDataGenerator for preprocessing and augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,            # Normalize pixel values\n",
    "    validation_split=0.2,      # Split dataset: 80% train, 20% validation\n",
    "    rotation_range=30,         # Random rotations\n",
    "    zoom_range=0.2,            # Random zoom\n",
    "    horizontal_flip=True       # Random horizontal flips\n",
    ")\n",
    "\n",
    "# Prepare training data generator\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(150, 150),  # Resize images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='training',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Prepare validation data generator\n",
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_path,\n",
    "    target_size=(150, 150),  # Resize images\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70552d37-b9fb-4a44-9f83-b0835331d316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the CNN model\n",
    "model = Sequential([\n",
    "    Input(shape=(150, 150, 3)),  # Input layer\n",
    "    Conv2D(32, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.5),  # Regularization to reduce overfitting\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')  # Output layer\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3af488-4c63-4098-85ea-59809dace432",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "# Define a custom callback to display remaining time\n",
    "class TimeRemainingCallback(Callback):\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self.train_start_time = time.time()  # Record the training start time\n",
    "\n",
    "    def on_epoch_begin(self, epoch, logs=None):\n",
    "        if epoch == 0:\n",
    "            self.epoch_start_time = time.time()  # Record the first epoch start time\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        current_time = time.time()\n",
    "        time_per_epoch = current_time - self.epoch_start_time\n",
    "        remaining_epochs = self.params['epochs'] - (epoch + 1)\n",
    "        estimated_time_remaining = time_per_epoch * remaining_epochs\n",
    "        \n",
    "        print(f\"\\nEpoch {epoch + 1}/{self.params['epochs']} completed.\")\n",
    "        print(f\"Time per epoch: {time_per_epoch:.2f} seconds.\")\n",
    "        print(f\"Estimated time remaining: {estimated_time_remaining:.2f} seconds.\\n\")\n",
    "\n",
    "        # Update epoch start time for the next epoch\n",
    "        self.epoch_start_time = current_time\n",
    "\n",
    "# Instantiate the custom callback\n",
    "time_remaining_callback = TimeRemainingCallback()\n",
    "\n",
    "# Train the model with the custom callback\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,  # Adjust epochs for better results\n",
    "    validation_data=validation_generator,  # Use validation data for evaluation\n",
    "    callbacks=[time_remaining_callback]  # Add the custom callback\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9189a4d-423b-4954-b7bb-330df80498e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on validation data\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Validation Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Plot training vs. validation accuracy\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training vs Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a22294f-e781-4d5f-b86b-bacf538b11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Plot the model architecture\n",
    "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a3c8f77-1ebb-4f58-b478-9ddeb3bcd790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual class counts from train_generator\n",
    "class_counts = np.unique(train_generator.classes, return_counts=True)[1]  # Count occurrences of each class\n",
    "class_labels = list(train_generator.class_indices.keys())  # Class names\n",
    "\n",
    "# Plot the class distribution\n",
    "plt.figure(figsize=(20, 15))\n",
    "plt.bar(class_labels, class_counts, color='skyblue')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class Labels')\n",
    "plt.ylabel('Number of Images')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc417554-8dd9-42c5-b5d4-5dc53bfc7147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def plot_sample_images(train_generator, num_images_per_class=5):\n",
    "    class_names = train_generator.class_indices.keys()\n",
    "    plt.figure(figsize=(15, len(class_names) * 3))\n",
    "    \n",
    "    for class_index, class_name in enumerate(class_names):\n",
    "        # Filter images belonging to the current class\n",
    "        class_image_paths = [img for img in train_generator.filenames if class_name in img]\n",
    "        random_images = random.sample(class_image_paths, min(len(class_image_paths), num_images_per_class))\n",
    "        \n",
    "        for i, img_path in enumerate(random_images):\n",
    "            # Load and display the image\n",
    "            img_full_path = os.path.join(train_generator.directory, img_path)\n",
    "            img = image.load_img(img_full_path, target_size=(150, 150))\n",
    "            plt.subplot(len(class_names), num_images_per_class, class_index * num_images_per_class + i + 1)\n",
    "            plt.imshow(img)\n",
    "            plt.title(class_name)\n",
    "            plt.axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function\n",
    "plot_sample_images(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a715f0-3578-4e72-b3ef-878bde952d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def analyze_image_sizes(generator):\n",
    "    widths = []\n",
    "    heights = []\n",
    "    \n",
    "    for img_path in generator.filenames:\n",
    "        img_full_path = os.path.join(generator.directory, img_path)\n",
    "        with Image.open(img_full_path) as img:\n",
    "            widths.append(img.width)\n",
    "            heights.append(img.height)\n",
    "\n",
    "    plt.figure(figsize=(4, 3))\n",
    "    plt.hist(widths, bins=30, alpha=0.5, label='Widths', color='blue')\n",
    "    plt.hist(heights, bins=30, alpha=0.5, label='Heights', color='orange')\n",
    "    plt.title('Distribution of Image Sizes')\n",
    "    plt.xlabel('Size (pixels)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Analyze image sizes\n",
    "analyze_image_sizes(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b30870-5c94-47ce-9ab3-3344ee2be1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the trained model\n",
    "# Assuming the model is already loaded and trained, and it's named 'model'\n",
    "# If not, you can load the model using model = tf.keras.models.load_model('model_path')\n",
    "\n",
    "# Load and preprocess an image for prediction\n",
    "img_path = r\"C:\\Users\\HP\\Downloads\\images.jpg\"  # Replace with the actual path to your test image\n",
    "\n",
    "# Resize the image to match model input size (assuming the model expects 150x150 size)\n",
    "img = image.load_img(img_path, target_size=(150, 150))  # Resize to model input size\n",
    "img_array = image.img_to_array(img) / 255.0  # Convert image to array and normalize pixel values\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension for prediction\n",
    "\n",
    "# Predict the disease class\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class_index = np.argmax(predictions, axis=1)[0]  # Get the index of the class with the highest probability\n",
    "\n",
    "# Map the predicted index to class labels\n",
    "class_names = list(train_generator.class_indices.keys())  # Get the class labels from the training data generator\n",
    "predicted_class = class_names[predicted_class_index]  # Get the predicted class name\n",
    "print(f\"The predicted class is: {predicted_class}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eb64e8-63b8-44d1-a152-461fb4fbc1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get the classification report with zero_division set to handle undefined precision\n",
    "report = classification_report(validation_labels, validation_predicted_classes, \n",
    "                               target_names=validation_generator.class_indices.keys(), zero_division=0)\n",
    "\n",
    "# Print the report\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40205eed-91e6-4bf0-b5d6-f882f69daa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model for future use\n",
    "model.save('plant_disease_cnn_model.h5')\n",
    "print(\"Model saved as plant_disease_cnn_model.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d1d070-35aa-4b9c-b303-c7f0dc1b2215",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
